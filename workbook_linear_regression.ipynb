{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workbook_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+ZLQPry35mx4VnZboYq4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgentWombat/height-weight-linear-regression/blob/main/workbook_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXnb3jUxNmZD"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "---\n",
        "\n",
        "Linear regression is perhaps the most basic use of machine learning. In this notebook you will learn what linear regression is and how to implement it from scratch in Python.\n",
        "\n",
        "The final product of this notebook will be a program which, given a person's weight in pounds, will predict his or her height in inches.\n",
        "\n",
        "### *What is linear regression*?\n",
        "\n",
        "Let us say I have a data set with the weight, in pounds, and height, in inches, for 100 different people. For me, as a person, to try and predict a man's height based purely on his weight, I consult this data and make a prediction accordingly. So, I compile the data into a graph like so:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1qkh2BCBmqha10EdmCW-QhdoVXjyluCtc)\n",
        "\n",
        "We notice that the data seesm to loosly fit a line; that is, I could draw a *line of best fit* in the data:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1sqycR27BLJmnXE-DgcqOT0Qi1nrAY_Oj)\n",
        "\n",
        "Now, if I know that my best friend Charles is 200 pounds, I could locate the corresponding height on the line and make a somewhat accurate prediction of his height:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1TqzAdEazrNSt3QyK4keJSdZl3qAOgZvD)\n",
        "\n",
        "This means that Charles is probably around 71 inches tall.\n",
        "\n",
        "I just used linear regression: I *regressed*, or simplified, the relationship between weight and height to a linear relationship (i.e. I drew a line in my data and, to predict height, found the height corresponding to the given weight on the line). In reality, build, sex, bone density, and more play roles (which are not neccisarily linear) in determining someone's height. But for my goal, *regressing* my problem of predicting height to a linear relationship between itself and weight results in sufficient accuracy.\n",
        "\n",
        "### *How can I quantify the above methods?*\n",
        "\n",
        "To get my computer to accomplish the task using similar methods, I must more rigouresly define what I am doing when I draw a line of best fit.\n",
        "\n",
        "A line is given by ```y = m * x + b``` and, for purposes of machien learning, the variable \"m\" will be subbed for \"w\" resulting in ```y = w * x + b```. If I have  values for \"w\" and \"b\", I can know \"y\" given any \"x\" by using the formula.\n",
        "\n",
        "With this definition of a line, I can say that when I draw a line of best fit, I am implicitly choosing values for \"w\" and \"b\". When I locate a height by going to the point on the line associated with a weight, I am implicitly evaluating my function ```y (height) = w * x (weight) + b``` for a specific value of x. For the line I drew above, it looks like the formula is approximately ```y = 3/20 * x + 41```. Evaluated at 200 lbs (x = 200), I get a height of 71 inches (y = 71).\n",
        "\n",
        "Secondarily, I must define exactly what makes a line a \"good\" or \"bad\" fit. To do this, I will define some function C(y, y_predictions) such that when a line is a good fit to the data it will have a low value; and when a line is a bad fit, the function will evaluate to a high value. One such fuction is called  *mean squared error (MSE)*.  MSE is defined as follows:\n",
        "\n",
        "```\n",
        "1/n * ∑(y_i - y_prediction_i)^2, where \"n\" is the number of data points and ∑ is summing over all data points.\n",
        "```\n",
        "\n",
        "MSE sums the squared differences between my guesses and their corresponding actual values. To visualize,\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1g6zrMENG7z6W-A5ASaP2E5Hn7W0MrVAP)\n",
        "\n",
        "The above image shows two out of the 100 squared distances which must be added to fully compute the cost.\n",
        "\n",
        "Going back to getting my computer to \"draw\" this line for me, what I need to do it get it to pick values for \"w\" and \"b\". Then, based on how well it performs with its picked values, as measured by MSE, it must update \"w\" and \"b\" such that the model is likely to make better predictions, as measured by MSE, next time. For this, I must use some basic calculus--mainly, the derivative. [Here is a link to a quick intro to derivatives.](https://machinelearningmastery.com/a-gentle-introduction-to-function-derivatives/) All that you really have to know is that the derivative of a function tells us whether increasing a variable will increase or decrease a function.\n",
        "\n",
        "The two derivative formulas needed for this task are given here:\n",
        "\n",
        "```\n",
        "C(y, y_pred) = 1/n * ∑(y_i - y_prediction_i)^2\n",
        "\n",
        "# But because y_prediction_i = w * x_i + b\n",
        "C(y, y_pred) = 1/n * ∑(y_i - (w * x_i + b))^2\n",
        "\n",
        "# Here are the two derivatives\n",
        "dC/dw  = 1/n ∑( -2 * x_i * (y_i - (w * x_i + b)) )\n",
        "dC/db = 1/n ∑( -2 * (y_i - (w * x_i + b)) )\n",
        "```\n",
        "\n",
        "\n",
        "### *How can I get my computer to do it?*\n",
        "\n",
        "**Step one** is to guess values for the parameters \"w\" and \"b\". I will program \"w\" to be 1/12 and \"b\" to be 53.\n",
        "\n",
        "My model is then given by the equation ```y = 1/12 * x + 53```.\n",
        "\n",
        "When graphed, these parameters look thus:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=16CRbvw-PL1XfDNAY90mhp4j2oVGOXFUm)\n",
        "\n",
        "**Step two** is to calculate the derivative of the cost function with respect to variables \"w\" and \"b\".\n",
        "\n",
        "For ```w = 1/12``` and ```b = 53```, and with 100 data points in my dataset, my equations would look like this:\n",
        "\n",
        "```\n",
        "dC/dw  = 1/100 ∑( -2 * x_i * (y_i - (1/12 * x_i + 53)) )\n",
        "dC/db = 1/100 ∑( -2 * (y_i - (1/12 * x_i + 53)) )\n",
        "```\n",
        "\n",
        "To evaluate these formulas, the calculation would look as follows:\n",
        "\n",
        "```\n",
        "dC/dw = 1/100 * (-2 * x_1 * (y_1 - 1/12 * x_1 + 53) + -2 * x_2 * (y_2 - 1/12 * x_2 + 53) +... -2 * x_100 * (y_100 - 1/12 * x_100 + 53))\n",
        "dC/db = 1/100 * (-2 * (y_1 - 1/12 * x_1 + 53) + -2 * (y_2 - 1/12 * x_2 + 53) +... -2 * (y_100 - 1/12 * x_100 + 53))\n",
        "\n",
        "Where x_1, x_2, x_3... are the first, second, third... inputs and y_1, y_2, y_3... are the first, second, third... outputs.\n",
        "```\n",
        "\n",
        "**Step three** is to update the values for \"w\" and \"b\" based on the gradients (derivatives). Because gradients give the direction of steepest ascent (i.e. the direction which most *increases* a variable), we subtract the gradients to best *decrease* the variables. \"learning_rate\" is some positive constant scalar value which controls how fast \"w\" and \"b\" are updated.\n",
        "\n",
        "```\n",
        "w = w - dC/dw * learning_rate\n",
        "b = b - dC/db * learning_rate\n",
        "```\n",
        "\n",
        "**Step four** is to repeat steps two and three until the parameter values \"w\" and \"b\" result in sufficient predictions.\n",
        "\n",
        "\n",
        "Now, it is time to code.\n",
        "\n",
        "The following program will use linear regression to make predictions of a person's height bases on his or her weight.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PAjs2N5Nlor"
      },
      "source": [
        "#  IMPORTS\n",
        "from matplotlib import pyplot as plt # To graph data\n",
        "import pandas as pd # To parse our data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-p2sy5Kw7xc"
      },
      "source": [
        "To get the weight/height dataset, go to [this webpage on kaggle](https://www.kaggle.com/mustafaali96/weight-height) and click \"Download\".\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1B8Lfed6C9FhTwVod7L7FfaKjAnxK9v98)\n",
        "\n",
        "You will recieve a compressed file format. To read this data, you first need to extract it (if your computer cannot extract/decompress the file format, install WinRAR and use it).\n",
        "\n",
        "After extracting the \"weight-height.csv\" file, drag it into the files section of this notebook.\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1_sjbaz3xuuaVO9sUCI8rbn3cCAmTe-bF)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m5VvqcdwwKm"
      },
      "source": [
        "# LOADING DATA\n",
        "\n",
        "# The data we downloaded contains the gender, height (in), and weight (lbs)\n",
        "# for 10,000 individuals. \n",
        "df = pd.read_csv(\"weight-height.csv\")\n",
        "\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYiP24N5zeHQ"
      },
      "source": [
        "# PARSE DATA\n",
        "\n",
        "# We will make the weight the explanitory variable (input)\n",
        "# and height the response varable (output)\n",
        "\n",
        "# Normally more data is better; but to speed up this notebook,\n",
        "# we will only use the first 100 data points \n",
        "x = list(df['Weight'])[:100]\n",
        "y = list(df['Height'])[:100]\n",
        "\n",
        "# Print the first 5 entrees of both x and y\n",
        "print(x[:5])\n",
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FQ6gDlD0Rlf"
      },
      "source": [
        "# GRAPH DATA\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel(\"Weight\")\n",
        "plt.ylabel(\"Height\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkooJBkO1LcF"
      },
      "source": [
        "With our data now parsed and ready to use, let us start development of our machine learning functionality\n",
        "\n",
        "All of the sections encapsulated by pound signs (#) are sections for you to fill in code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4rT0Ll1H5x"
      },
      "source": [
        "# DEFINE forward_pass\n",
        "# When we evaluate all our datapoints using our model, we call it a forward pass\n",
        "\n",
        "def forward_pass(x: list, params: dict) -> list:\n",
        "\t'''\n",
        "\tCalculates one forward pass for a linear model. For example, if 'w' = 2 and\n",
        "    'b' = 0, then an input (x) of [1,2,3] would result in an output of [2,4,6].\n",
        "\n",
        "\t:param x: The input data. Should be a 1D list\n",
        "\t:param params: A dictionary which contains the parameters of the linear model:\n",
        "\t\t'w' - the weight for inputs 'x'\n",
        "\t\t'b' - the bias\n",
        "\t:returns: The outputs for inputs 'x'.\n",
        "\t'''\n",
        "\n",
        "\t# Unpack parameters from dictionary\n",
        "  # CODE ~2 lines\n",
        "  ########################################\n",
        "\tw = params[None]\n",
        "\tb = params[None]\n",
        "  ########################################\n",
        "\n",
        "\t# The outputs\n",
        "\ty_hat = []\n",
        "\n",
        "\t# Calculate outputs for each input\n",
        "\tfor val in x:\n",
        "    # CODE ~1 line\n",
        "    ########################################\n",
        "\t\ty_hat.append(None)\n",
        "    ########################################\n",
        "\n",
        "\treturn y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjzSGq6D1yLD"
      },
      "source": [
        "# TEST forward_pass\n",
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "params_test = {\"w\": 10, \"b\": 5}\n",
        "x_test = [1,2,3,4]\n",
        "y_test = [15, 25, 35, 45]\n",
        "\n",
        "y_hat_test = forward_pass(x_test, params_test)\n",
        "\n",
        "if y_test == y_hat_test:\n",
        "  print(\"TEST PASSED\")\n",
        "else:\n",
        "  print(\"TEST FAILED\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbuAJ1v4MtM"
      },
      "source": [
        "# DEFINE get_cost\n",
        "\n",
        "# Remember, the cost function measures how good or bad a model is performing\n",
        "\n",
        "def get_cost(y: list, y_hat: list) -> float:\n",
        "\t'''\n",
        "\tCalculates the mean squared error for predictions.\n",
        "\n",
        "\t:param y: The actual outputs.\n",
        "\t:param y_pred: The predicted outputs.\n",
        "\t:returns: The cost of the predictions\n",
        "\t'''\n",
        "\tcost = 0.0\n",
        "\n",
        "\t# Sum the costs for each output/prediction pair\n",
        "\tfor (y_i, yh_i) in zip(y, y_hat):\n",
        "\n",
        "    # CODE ~1 line\n",
        "    # Refer to the introduction for the MSE formula\n",
        "    ########################################\n",
        "\t\tcost += None\n",
        "    ########################################\n",
        "\n",
        "\t# Average the costs\n",
        "  # CODE ~1 line\n",
        "  ########################################\n",
        "\tcost = cost / None\n",
        "  ########################################\n",
        "\n",
        "\treturn cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZNl_6O7no_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWSThN-Y4gib"
      },
      "source": [
        "# TEST get_cost\n",
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "y_test = [2, 3, 4]\n",
        "\n",
        "y_hat_test = [1, 1, 8]\n",
        "\n",
        "cost_test = get_cost(y_test, y_hat_test)\n",
        "\n",
        "if cost_test == 7:\n",
        "  print(\"TEST PASSED\")\n",
        "else:\n",
        "  print(\"TEST FAILED\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_jw0JFe5t7T"
      },
      "source": [
        "# DEFINE backward_pass\n",
        "\n",
        "# The backward pass calculates and returns the derivatives of the model's\n",
        "# parameters\n",
        "\n",
        "def backward_pass(x: list, y: list, params: dict) -> dict:\n",
        "\t'''\n",
        "\tCompletes one step of backward propagation for a linear model\n",
        "\t\tusing MSE as the cost function. \n",
        "\n",
        "\t:param x: The input data.\n",
        "\t:param y: The output data.\n",
        "\t:param params: A dictionary which contains the parameters of the linear model:\n",
        "\t\t'w' - the weight for inputs 'x'\n",
        "\t\t'b' - the bias\n",
        "\t:returns: A dictionary containing the gradient for each paramater:\n",
        "\t\t'dw' - The derivative of the cost function with respect to 'w' (dC/dw)\n",
        "\t\t'db' - The derivative of the cost function with respect to 'b' (dC/db)\n",
        "\t'''\n",
        "\n",
        "\t# Unpack parameters from dictionary\n",
        "\tw = params['w']\n",
        "\tb = params['b']\n",
        "\n",
        "\t# dC/dw\n",
        "\tdw = 0.0\n",
        "\n",
        "\t# dC/db\n",
        "\tdb = 0.0\n",
        "\n",
        "\t# Sum gradients for each input/output pair\n",
        "\tfor x_i, y_i in zip(x, y):\n",
        "\n",
        "\t\t# Both of these formula are the formula for \n",
        "\t\t# the derivative of the cost function with respect\n",
        "\t\t# to 'w' and 'b' respectively\n",
        "\n",
        "    # CODE ~2 lines\n",
        "    # Refer to the introduction for derivative formulas\n",
        "    ########################################\n",
        "\t\tdw += None\n",
        "\t\tdb += None\n",
        "    ########################################\n",
        "\n",
        "\t# Average the sum of the gradients\n",
        "  # CODE ~2 lines\n",
        "  ########################################\n",
        "\tdw = dw / None\n",
        "\tdb = db / None\n",
        "  ########################################\n",
        "\n",
        "\tgrads = {'dw': dw, 'db': db}\n",
        "\n",
        "\treturn grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V8uTjuv6AMW"
      },
      "source": [
        "# TEST backward_pass\n",
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "params_test = {'w': 5, 'b': 3}\n",
        "\n",
        "x_test = [1,2,3]\n",
        "\n",
        "y_test = [2,3,4]\n",
        "\n",
        "grads_test = backward_pass(x_test, y_test, params_test)\n",
        "\n",
        "if int(grads_test['dw']) == 45 and int(grads_test['db']) == 20:\n",
        "  print(\"TEST PASSED\")\n",
        "else:\n",
        "  print(\"TEST FAILED\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOEDdul98cJh"
      },
      "source": [
        "# DEFINE train\n",
        "\n",
        "# This function pieces together our previously created functions into cohesive\n",
        "# unit\n",
        "\n",
        "def train(x: list, y: list, params: dict, epochs: int = 1,\n",
        "\tlearning_rate: float = 0.000025, vocal = True) -> tuple:\n",
        "\t'''\n",
        "\tTrains parameters to a linear model (i.e. y = w * x + b).\n",
        "\n",
        "\t:param x: The input data.\n",
        "\t:param y: The output data.\n",
        "\t:param params: A dictionary which contains the parameters of the linear model:\n",
        "\t\t'w' - the weight for inputs 'x'\n",
        "\t\t'b' - the bias\n",
        "\t:param epochs: The number of training itterations.\n",
        "\t:param learning_rate: The number which multiply's the gradiants to update parameters.\n",
        "\t\tIf the 'learning_rate' is too large, the model will not train properly.\n",
        "\t:param vocal: If true, the function prints the current cost of the model to the standard\n",
        "\t\toutput every 500 epochs.\n",
        "\t:returns: (new_params, cost_history) where 'new_params' is the new and trained\n",
        "\t\tset of parameters and 'cost_history' is a list containing the cost\n",
        "\t\tafter each epoch.\n",
        "\t'''\n",
        "\n",
        "\t# Copy params dictionary to avoid side effects.\n",
        "\tnew_params = params.copy()\n",
        "\n",
        "\tcost_history = []\n",
        "\n",
        "\t# Update paramaters 'epochs' times\n",
        "\tfor i in range(epochs):\n",
        "\n",
        "    # CODE ~3 lines\n",
        "    ########################################\n",
        "\t\ty_hat = forward_pass(None, None)\n",
        "\t\tcost = get_cost(None, None)\n",
        "\t\tgrads = backward_pass(None, None, None)\n",
        "    ########################################\n",
        "\n",
        "\t\t# Print cost status\n",
        "\t\tif vocal and i % 500 == 0:\n",
        "\t\t\tprint(cost)\n",
        "\n",
        "\t\t# Unpack gradients\n",
        "\t\tdw = grads['dw']\n",
        "\t\tdb = grads['db']\n",
        "\t\n",
        "\t\t# Update weight and bias\n",
        "    # CODE ~2 lines\n",
        "    # Do not forget the learning rate\n",
        "    ########################################\n",
        "\t\tnew_params['w'] -= None\n",
        "\t\tnew_params['b'] -= None\n",
        "    ########################################\n",
        "\n",
        "\t\tcost_history.append(cost)\n",
        "\n",
        "\treturn new_params, cost_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JFvxh5E8vjj"
      },
      "source": [
        "# TEST train\n",
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "params_test = {'w': 5, 'b': 3}\n",
        "\n",
        "x_test = [1,2,3,4,30]\n",
        "\n",
        "y_test = [3,5,7,9,61]\n",
        "\n",
        "new_params_test, cost_history_test = train(x_test, y_test, params_test, 200000,\n",
        "                                           vocal = False)\n",
        "\n",
        "print(new_params_test)\n",
        "\n",
        "plt.plot(cost_history_test[1000:])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('cost')\n",
        "plt.show()\n",
        "\n",
        "if abs(new_params_test['w'] - 2) < 0.1 and abs(new_params_test['b'] - 1) < 0.1:\n",
        "  print(\"TEST PASSED\")\n",
        "else:\n",
        "  print(\"TEST FAILED\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMA8kWaZ_rOz"
      },
      "source": [
        "We now have all of the functions neccisary to accomplish our goal of predicting one's height based on his or her weight.\n",
        "\n",
        "Below, we will make the final implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sL4JFJsABmW"
      },
      "source": [
        "# Select starting parameters\n",
        "# These could be anything; however, the closer our initial guess it to being\n",
        "# correct, the faster the model will train.\n",
        "params = {'w': 0.2, 'b': 50}\n",
        "\n",
        "# We will now train our model on our data.\n",
        "# Remember, earlier we placed our data into the variables 'x' and 'y'.\n",
        "params, cost_history = train(x, y, params, epochs = 10000, vocal = False)\n",
        "\n",
        "# display results from training\n",
        "print(params)\n",
        "\n",
        "# Graph cost decay\n",
        "plt.plot(cost_history[25:])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "\n",
        "# Graph data\n",
        "plt.scatter(x, y)\n",
        "\n",
        "# Graph predictions\n",
        "plt.plot([150, 250], [params['w'] * 150 + params['b'], params['w'] * 250 + params['b']])\n",
        "plt.xlabel('Weight')\n",
        "plt.ylabel('Height')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT4h8YahEGks"
      },
      "source": [
        "# This is a simple program which uses our found parameters\n",
        "\n",
        "while True:\n",
        "\n",
        "\t\tuser_input = input('Input the wieght of a person in' +\n",
        "\t\t\t' pounds and I will predict his/her height. Enter' + \n",
        "\t\t\t' \"EXIT\" and this program will end.\\n>> ')\n",
        "\n",
        "\t\tif user_input == 'EXIT':\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tweight = float(user_input)\n",
        "\n",
        "\t\t\tprediction = forward_pass([weight], params)\n",
        "\n",
        "\t\t\tprint(f\"The corresponding person is {prediction[0]} inches tall.\\n\")\n",
        "\n",
        "\t\texcept ValueError:\n",
        "\n",
        "\t\t\tprint('Invalid input. Please try again')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}